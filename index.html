
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="D.jpg" height="5">
  <title>Dheeraj Singh</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Dheeraj Singh</name>
        </p>
        <p>I am second-year data science graduate student in the <a href="https://www.soic.indiana.edu/" target="_blank">School of Informatics, Computing, and Engineering</a> at the <a href="https://www.indiana.edu/" target="_blank">Indiana University, Bloomington</a>. I have keen interest in machine learning and its application in computer vision, natural language processing, and data science. My graduate course curriculum includes Elements of Artificial Intelligence, Applied Algorithms, Statistical Inference, Data Mining, Exploratory Data Analysis, Machine Learning in Computational Linguistics, Machine Learning in Signal Processing, Advance Database Concepts.
        </p>
        <p>
          Prior to my graduate studies, I was working as a Senior Project Associate at the <a href="http://iitk.ac.in/" target="_blank">Indian Institute of Technology (IIT) - Kanpur</a> where I developed a Data Visualization Web Application under the advice of <a href="https://www.cse.iitk.ac.in/users/arnabb/" target="_blank">Prof. Arnab Bhattacharya</a> and a Vehicle Recognition System under the supervision of <a href="http://home.iitk.ac.in/~gpandey/" target="_blank">Prof. Gaurav Pandey</a>. I have previously worked with <a href="https://www.ipsos.com/en" target="_blank">Ipsos Research</a>, a leading global market research firm at Bangalore office and two technology startups: Tinyowl (now, merged with <a href="https://runnr.in/" target="_blank">Runnr</a>) with the business intelligence team and at <a href="https://www.embibe.com/" target="_blank">Embibe</a> with the data team. I have completed my undergraduate studies from the <a href="http://www.iitkgp.ac.in/" target="_blank">Indian Institute of Technology (IIT) - Kharagpur</a> in 2013.
        </p>
        <p align=center>
          <a href="mailto:dhsingh@iu.edu">Email</a> &nbsp|&nbsp
          <a href="resume-final.pdf">CV</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/dheeraj2444/" target="_blank">LinkedIn</a> &nbsp|&nbsp
          <a href="https://github.com/Dheeraj2444" target="_blank">Github</a> 
          <!-- <a href="https://www.kaggle.com/dheerajsingh2444" target="_blank">Kaggle</a>   -->
        </p>
        </td>
        <td width="33%">
        <img src="photo.jpg" height="250">
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>
    <heading>Skills</heading>
    <ul>
    <li><em><font color="#4875B4">Machine Learning:</font></em> Classification, Regression, Clustering, Recommendation System, Text Minig, Bayesian Inference, Natural Language Processing, Computer Vision</li>
    <li><em><font color="#4875B4">Methodologies:</font></em> Linear/Logistic Regression, Decision Trees, Random Forest, SVM, Naive Bayes, Ensemble Methods, K-Means, DBSCAN, Agglomerative Hierarchical, KNN, Bag-of-Words, Collaborative Filtering, Deep Neural Networks, Convolutional Neural Networks (CNN), RNN, LSTM, Transfer Learning</li>
    <li><em><font color="#4875B4">Programming Languages:</font></em> Python, R, Cython, MATLAB, Bash</li>
    <li><em><font color="#4875B4">Libraries and Software:</font></em> NumPy, Pandas, Scikit-Learn, SciPy, Pytorch, TensorFlow, Keras, NLTK, Spark, dplyr, Git, Vim</li>
    <li><em><font color="#4875B4">Data Visualization:</font></em> Seaborn, Matplotlib, Jupyter Notebook, ggplot</li>
    <li><em><font color="#4875B4">Web Development:</font></em> PHP, HTML, CSS, Javascript, Bootstrap</li>
    <li><em><font color="#4875B4">Databases:</font></em> PostgreSQL, MySQL, MongoDB, Neo4j</li>
    <li><em><font color="#4875B4">Operating Systems:</font></em> Mac OSX, Linux, Windows</li>
    </ul>
  </td></tr>
</table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Experience</heading>
        
        </td>
      </tr>
      </table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    
     <tr>
      <td width="25%">
        <img src='altair.jpg' height="40">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://www.altair.com/" target="_blank">
          <papertitle>Altair Engineering Inc.</papertitle></a><br>
          <em>Machine Learning Intern</em>, May'18 - Aug'18 <br>
    <p></p>
          <p>During the my internship at Altair, I worked on multiple projects. In my first project,
            I developed a 3D shape recognition system using voxelization and 3D Convolutional Neural Nets (CNN) resulting in 87% accuracy on the <a href="http://modelnet.cs.princeton.edu/" target="_blank">Princeton ModelNet10</a> (CAD models) dataset. In the second project, I built a multi-layered neural network to predict the failure of an Air Pressure System (APS) for <a href="https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks" target="_blank">Scania Trucks</a> in order to minimize the maintenance cost (Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)). The resulting models's performance was better than the results of teams that stood second and third in the competition. In another project, I built a system using deep neural nets to predict reduction in mass for a given geometry and load condition in order to achieve an optimized structure which could potentially reduce human efforts needed to run multiple simulation runs.</p>
        </td>
      </tr>


    <tr onmouseout="friendly_stop()" onmouseover="friendly_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'friendly_image'><img src='chart2.png' width="180" height="80"></div>
        <img src='chart1.png' width="180">
        </div>                
        <script type="text/javascript">
        function friendly_start() {
        document.getElementById('friendly_image').style.opacity = "1";
        }
        function friendly_stop() {
        document.getElementById('friendly_image').style.opacity = "0";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p>
        <a><papertitle>Data Visualization Web Application</papertitle></a><br>
          Advised by <a href="https://www.cse.iitk.ac.in/users/arnabb/" target="_blank">Prof. Arnab Bhattacharya</a><br>
        <em>Indian Institute of Technology (IIT) - Kanpur</em>, Dec'16 - May'17 <br>
        <em>PHP, MySQL, HTML, CSS, Bootstrap framework</em>
        <p>Developed a web-based user interactive application in <em>PHP</em> for real-time management and visualization of data stored in <em>MySQL</em> database. Defined the complete database schema, configured, and deployed the same using <em>phpMyAdmin</em>. Implemented device responsiveness and interoperability using the <em>Bootstrap framework</em>. Integrated the <em>Google chart</em> API to visualize the variability of data parameters in terms of distribution, trend, correlation, deviation, ratio, and frequency</p>
        <p></p>
      </td>
    </tr>
	
    <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'hdrnet_image'><img src='a4_scaled_new.jpg' width="150"></div>
        <img src='a4.jpg' width="150">
        </div>                
        <script type="text/javascript">
        function hdrnet_start() {
        document.getElementById('hdrnet_image').style.opacity = "1";
        }
        function hdrnet_stop() {
        document.getElementById('hdrnet_image').style.opacity = "0";
        }
        hdrnet_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p>
        <a><papertitle>Vehicle Recognition System</papertitle></a><br>
        Advised by <a href="http://home.iitk.ac.in/~gpandey/" target="_blank">Prof. Gaurav Pandey</a><br>
        <em>Indian Institute of Technology (IIT) - Kanpur</em>, April'16 - Nov'16 <br>
        <em>Python, OpenCV, Computer Vision</em>
        <p>Built a Python based OCR system to identify characters of number plates employing template matching framework. Performed various image processing activities, such as <em>Morphological transformations, Adaptive histogram equalization, contour formation</em> etc. using <em>OpenCV</em> library. The algorithm iterates over different pixel values as a threshold for binarization of gray-scaled images. The segmented binarized characters are then compared with existing templates for identification. It produced an accuracy of 83% in comparison to 76% with the existing one when tested over 1000 images.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <img src='TinyOwl-Logo.jpg' height="160">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://www.linkedin.com/company-beta/3863243/" target="_blank">
          <papertitle>Tinyowl Technologies - Food-tech Startup</papertitle></a><br>
          <em>Senior Business Analyst</em>, May'15 - Feb'16 <br>
	  <p></p>
          <p>I led several high-impact projects aimed towards growth. I collaborated with the marketing team to develop systems that drove the marketing efforts. In the process, I built a <em>Logistic Regression Model</em> to predict the propensity of user retention and developed a system employing <em>k-means clustering</em> for consumer segmentation to mimic consumption patterns in order to optimize marketing ROI. During my tenure, I also devised an algorithm aimed to rank restaurants based on their performance where I implemented scoring algorithm using Gini coefficients and centroid method to allocate weights to different contributing factors. In one of my project, I built an internal dashboard to visualize and track multiple business metrices using <em>shiny</em> package in R.</p>
        </td>
      </tr>

      <tr>
      <td width="25%">
        <img src='embibe-logo.png' height="140">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://www.embibe.com/" target="_blank">
          <papertitle>Embibe - Education-tech Startup</papertitle></a><br>
          <em>Business Analyst</em>, Jan'15 - April'15 <br>
    <p></p>
          <p>The stint at Embibe required me to don multiple hats, a trait very typical of early stage startups. I worked on an array of projects ranging from cohort analysis of user base, deriving useful insights from raw data for pitching deck for investors, maintenance of Management Information System (MIS), improving & updating database schema to even writing python scripts for automation, writing r scripts to meet any ad-hoc data requirements. As the organization matured, I was responsible for addressing every data related issue within it.</p>
        </td>
      </tr>

      <tr>
      <td width="25%">
        <img src='Ipsos-logo.png' height="90">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://www.ipsos.com/en" target="_blank">
          <papertitle>Ipsos - Market Research firm</papertitle></a><br>
          <em>Analyst</em>, Jan'13 - Dec'14 <br>
    <p></p>
          <p>I worked as a Market Research Analyst for IPSOS. As part of my job profile, I conducted brand tracking and Return-on-Investment evaluation per marketing tactic by creating and assessing <em>Market Mix Models</em> of various market scenarios. I also developed optimization strategies for effective marketing expenditure and developed <em>predictive models</em> to forecast accrued profits. I worked in a global team and collaborate on a day-to-day basis with my offshore colleagues based in New York and Connecticut. I have also acted on numerous occasions as key accounts manager for my firm serving numerous global clients in a variety of domains covering retail, CPG, pharmaceuticals, restaurant chains. For my outstanding perfomance, I was also awarded with <em>Spot Performer</em> of Q3'2014 in the analytics domain.</p>
        </td>
      </tr>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">

      <tr>
        <td width="25%"><img src="siamese.png" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/deeplearning-coursera" target="_blank">
          <papertitle>Speaker Identification and Verification</papertitle>
          </a><br>
          <em>Signal Processing, STFT, VoxCeleb Dataset, VGGVox, Python, Pytorch, Siamese Networks</em>
          <p>
          Designed a Siamese network based on VGGVox model as sister networks sharing common set of weights. Trained the model on VoxCeleb dataset on AWS. Performed transfer learning and used pretrained weights of the VGGVox model. The VoxCeleb dataset contains speech from speakers spanning a wide range of different ethnicities, accents, professions and ages. It consists of 100K utterances for 1,251 celebrities. Transformed recordings to a magnitude spectogram using STFT, with a frame size of 15 milliseconds and na overlap of 15 milliseconds. Achieved 0.78 precision \& 0.84 recall. Developed a terminal application for identification and verification in real time.
        </p>
        </td>
      </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">

      <tr>
        <td width="25%"><img src="deep_ai.png" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/deeplearning-coursera" target="_blank">
          <papertitle>Deep Learning Specialization</papertitle>
          </a><br>
          <em>Python, TensorFlow, Keras, Deep Neural Networks, Convolutional Neural Networks, RNN, LSTM</em>
          <p>
          Working towards deep learning specialization course provided by deeplearning.ai and Coursera. Worked on projects involving the implementation of deep neural networks from scratch, exploring and tuning multiple hyperparameters of neural networks, different optimization techniques, regularization methods; trained deep neural network on SIGNS dataset to identify hand gesture from a given image. RNN, LSTM architectures using word embeddings (Word2Vec, Glove) for sequence modeling, NLP in particular. 
        </p>
        </td>
      </tr>

      
      <tr>
        <td width="25%"><img src="cifar-10.png" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/pytorch" target="_blank">
          <papertitle>Image Classification</papertitle>
          </a><br>
          <em>Pytorch, CIFAR-10, Transfer Learning, AlexNet, VGG16, ResNet</em>
          <p>
            Explored different deep learning architectures, namely, AlexNet, VGG16, ResNet. Built an image classification model using transfer learning and fine-tuning in Pytorch. AlexNet-78%, VGGNet-85%, ResNet-83% on 10K test images.
          </p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="spark-streaming.png" alt="prl" width = "210"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/spark" target="_blank">
          <papertitle>Spark Streaming</papertitle>
          </a><br>
          <em>DStreams, RDD, MapReduce, Twitter API, PySpark, Tweepy</em>
          <p>
            Built an application using Twitter API, Tweepy, and PySpark to connect with Twitter and process live incoming tweets in order to visualize top trending hashtags associated with a given topic 
          </p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="graph-search.jpg" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/course-projects/tree/master/optimal-path-search" target="_blank">
          <papertitle>Optimal Path Search</papertitle>
          </a><br>
          <em>Python, Graph Search</em>
          <p>
          Worked on a project aimed at finding the most optimal route between a given pair of cities of the United States. Compared different Graph Search Algorithms, namely, Breadth First Search, Depth First Search, Uniform Cost Search, and A-star on the basis of path cost, time, & space requirements for multiple cost functions
        </p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="hmm.png" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/course-projects/tree/master/part-of-speech-tagging" target="_blank">
          <papertitle>Part-of-Speech (POS) Tagging</papertitle>
          </a><br>
          <em>Python, Hidden Markov Model, Bayes Net, Naive Bayes, Bag-of-words</em>
          <p>
          Developed a model to perform part-of-speech tagging in English language using Hidden Markov Model, Bayesian inferences, and naive Bayes. Trained the model to calculate initial, transition, emission, and state probabilities on a data consisting of nearly 1 million words and 50,000 sentences. Implemented and compared the performance of Variable Elimination (Forward-Backward Algorithm) and Viterbi Algorithm. Final model resulted in above 50% sentence accuracy and above 90% word accuracy when tested over 2000 sentences.
        </p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="Bayes_rule.png" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/course-projects/tree/master/tweet-classification" target="_blank">
          <papertitle>Tweet Classification</papertitle>
          </a><br>
          <em>Python, Text-Mining, Naive Bayes, Bag-of-words</em>
          <p>
          Developed a Naive Bayes classifier to identify the location from where the tweet was written by maximizing the likelihood in order to compare posteriors of all cities. Implemented Multinomial Document Model using bag-of-words and Laplace Smoothening for missing tokens
        </p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="n-queens.png" alt="prl"  height = "100"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/course-projects/tree/master/n-queens" target="_blank">
          <papertitle>N-Queens / N-Rooks Solver</papertitle>
          </a><br>
          <em>Python, DFS, BFS</em>
          <p>
          Developed a N-Queens and N-Rooks solver incorporating Breadth First Search and Depth First Search algorithms
        </p>
        </td>
      </tr>

      <!-- </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Small Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20"> -->
      
      <tr>
        <td width="25%"><img src="collaboative-filtering.png" alt="prl" width = "180" height="200"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/Movie-Recommendation-System" target="_blank">
          <papertitle>Movie Recommedation System</papertitle>
          </a><br>
          <em>Python, Collaborative Filtering</em>
          <p>
          Built a Movie Recommendation System in Python based on <em>Collaborative Filtering</em> algorithm that uses <em>Euclidean Distance</em> or <em>Pearson Coefficient</em> to find similar users and returns the list of top recommended movies for a given user. It takes method to be used to find similar users and a number of movies to be recommended as a command line argument. Used MovieLens movies rating dataset from <a href="http://grouplens.org/datasets/movielens/" target="_blank">GroupLens</a>.
        </p>
        </td>
      </tr>

  <!--     <tr>
        <td width="25%"><img src="kaggle-logo.png" alt="prl" width="180" ></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://www.kaggle.com/dheerajsingh2444/competitions" target="_blank">
          <papertitle>Kaggle Competitions</papertitle>
          </a><br>
          <em>Python, R, Decision Trees, Random Forest, SVM, Naive Bayes, ANN, XgBoost, K-fold Cross Validation, Feature Engineering</em>
        <p>
          Trained and tested numerous prediction and classification models using supervised and unsupervised learning, namely, <em>Decision Trees, Random Forest, SVM, Xgboost</em>. Performed <em>K-fold Cross Validation</em> to avoid over-fitting. Performed data manipulation techniques like <em>missing value imputation, outliers removal, feature engineering</em>
        <ul>
          <a href="https://www.kaggle.com/c/sf-crime" target="_blank"><li>San Francisco Crime Classification</li></a>
          <a href="https://www.kaggle.com/c/walmart-recruiting-trip-type-classification" target="_blank"><li>Walmart Trip Type Classification</li></a>
          <a href="https://www.kaggle.com/c/prudential-life-insurance-assessment" target="_blank"><li>Prudential Life Insurance Assessment</li></a>
          <a href="https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings" target="_blank"><li>Airbnb New User Bookings</li></a>
        </ul>
        </p>
        </p>
        </td>
      </tr> -->
  <!--     
      <tr>
        <td width="25%"><img src="sentiments.jpg" alt="prl" width = "180"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/Twitter-API-SentimentAnalysis-WordCloud-WordsFrequecy" target="_blank">
          <papertitle>Sentiment Analysis and Word Cloud</papertitle>
          </a><br>
          <em>R, tm package, Natural Language Processing</em>
          <p>
          This project was aimed at classifying tweets into positive and negative sentiments. I employed <em>bag-of-words</em> and rule-based approach facilitated by opinion lexicons available <a href=" https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html" target="_blank"> here </a>to apportion scores to words in a tweet. Tweets were cleaned using bag-of-words. The cumulative scores were driven by occurrences of predefined (set of 6800) positive and negative English words. This is the compiled list of <strong>(Hu and Liu, KDD-2004)</strong> starting from their first paper.The final score thus obtained was then used to tag a tweet as positive (score>0), neutral (score=0), and negative (score<0).
        </p>
        </td>
      </tr> -->
<!-- 
      <tr>
        <td width="25%"><img src="k-means.jpg" alt="prl" width="180" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a><papertitle>Speaker Recognition System</papertitle></a>
          <br>
          <em>R, TuneR Package, K-Means Clustering, MFCC features</em>
        <p>
          Built a speaker recognition system to identify time points of the change in a speaker for a given conversation (used YouTube videos) using <em>K-means clustering</em>. Included <em> MFCC</em> and <em>delta coefficients</em> as features vector. Performed pre-processing of Youtube vidoes and then of audio signals using <em>tm</em> package in R
        </p>
        </p>
        </td>
      </tr> -->

      

    <!--   <tr>
        <td width="25%"><img src="web-scraping.png" alt="prl" width="150" height="150"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/Dheeraj2444/Linkedin-Web-Crawler" target="_blank">
          <papertitle>LinkedIn Job Finder</papertitle>
          </a><br>
          <em>Python, BeautifulSoup Package</em>
        <p>
          Built a LinkedIn Scraper that takes job title e.g. 'Business Analyst', 'Machine Learning', or any combination of words and the number of pages to crawl as a command line argument from user and returns the list of all jobs along with job portal, job title, location, and company name matching those keywords. Used <em>BeautifulSoup</em> module in <em>Python</em>. This tool can be helpful for tedious job searches.
        </p>
        </p>
        </td>
      </tr> -->

      </table>
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <br>
        <p align="right"><font size="2">
      Credits: <a href="https://people.eecs.berkeley.edu/~barron/" target="_blank">Jon Barron</a>
          </font>
        </p>
        </td>
      </tr>
      </tbody></table>
    </td>
    </tr>
  </tbody></table>


  </body>
</html>
